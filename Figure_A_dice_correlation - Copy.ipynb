{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dice coefficient, ARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\My Drive\\\\Results\\\\\\\\CAPS\\\\cluster_stats\\\\data_table_40.csv'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = 'CAPS'\n",
    "results_path = r\"G:\\My Drive\\Results\\\\\" + experiment + r\"\\cluster_stats\"\n",
    "number_of_clusters = 40\n",
    "data_table_path = os.path.join(results_path, 'data_table_' + str(number_of_clusters) + '.csv')\n",
    "data_table_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(project_dict, number_of_clusters):\n",
    "    # This function returns a dictionary with the clusters and a list with the cluster IDs\n",
    "\n",
    "    mask = \"b_GreyMatter2mm\"\n",
    "    corr_type = \"t\" #takes t or s\n",
    "    \n",
    "\n",
    "    username = project_dict['User']\n",
    "    if os.name == 'nt':\n",
    "        datafolder = r\"P:\\userdata\" + os.sep + username + r\"\\data\"\n",
    "        datafolder = r\"C:\\data\"\n",
    "    else:\n",
    "        datafolder = '/home' + os.sep + username + '/mnt/a471/userdata/' + username + '/data'\n",
    "\n",
    "    cluster_map_path = os.path.join(datafolder, project_dict['Dataset'], 'hierarchical_clustering',\n",
    "                            project_dict['Specie'] + '-group-' + corr_type + 'corr-' + mask + '_' + str(number_of_clusters) + '.nii.gz')\n",
    "\n",
    "    # Load the cluster map\n",
    "    cluster_map = nib.load(cluster_map_path).get_fdata()\n",
    "\n",
    "    # generate list of clusters\n",
    "    clusters_ID_list = list(set(cluster_map.flatten()))\n",
    "    # remove 0 from the list\n",
    "    clusters_ID_list.remove(0)\n",
    "\n",
    "    # transform the cluster map into a vector\n",
    "    cluster_map = cluster_map.flatten()\n",
    "\n",
    "    clusters = {}\n",
    "    # find the position of each element in the cluster_ID_list\n",
    "    for cluster_ID in clusters_ID_list:\n",
    "        clusters[cluster_ID] = [i for i, x in enumerate(cluster_map) if x == cluster_ID]\n",
    "    \n",
    "    return clusters,clusters_ID_list\n",
    "\n",
    "\n",
    "def get_homogeinity(project_dict,sub_N,vox_list):\n",
    "    # This function calculates the homogeneity of a parcellation\n",
    "    # project_dict: dictionary with the project information\n",
    "    # sub_N: subject number\n",
    "    # vox_list: list of voxels in the cluster\n",
    "\n",
    "    username = project_dict['User']\n",
    "    if os.name == 'nt':\n",
    "        datafolder = r\"P:\\userdata\" + os.sep + username + r\"\\data\"\n",
    "        datafolder = r\"C:\\data\"\n",
    "    else:\n",
    "        datafolder = '/home' + os.sep + username + '/mnt/a471/userdata/' + username + '/data'\n",
    "\n",
    "    # path to the functional nii file\n",
    "    func_path = os.path.join(datafolder, project_dict['Dataset'], 'normalized', project_dict['Specie'] + '-sub-' + str(sub_N).zfill(3),\n",
    "                            project_dict['Specie'] + '-sub-' + str(sub_N).zfill(3) + '_task-' + project_dict['Task'] + '_run-' + str(project_dict['Runs'][0]).zfill(2) + '.nii.gz')\n",
    "\n",
    "    # load the nii file\n",
    "    func_nii = nib.load(func_path).get_fdata()\n",
    "\n",
    "    # load the nii file\n",
    "    func_nii = nib.load(func_path).get_fdata()\n",
    "    # flatten func_nii keeping the time dimension (4th dimension)\n",
    "    func_nii_flat = np.reshape(func_nii, (-1, func_nii.shape[-1]))\n",
    "\n",
    "    # initialize the corr_list\n",
    "    # results = []\n",
    "    corr_list = []\n",
    "\n",
    "    for n,nVox1 in enumerate(vox_list):\n",
    "        for nVox2 in vox_list[n+1:]:\n",
    "            #getting the time series for both voxels\n",
    "            time_series1 = func_nii_flat[nVox1]\n",
    "            time_series2 = func_nii_flat[nVox2]\n",
    "                \n",
    "            # Calculate the Pearson correlation between the two time series\n",
    "            corr = np.corrcoef(time_series1, time_series2)[0, 1]\n",
    "            # if corr is nan, continue to the next iteration\n",
    "            if np.isnan(corr):\n",
    "                continue\n",
    "            \n",
    "            corr_list.append(corr)\n",
    "            # Store the results\n",
    "            # results.append([nVox1, nVox2, corr])\n",
    "\n",
    "    # calculate average correlation\n",
    "    average_corr = np.mean(corr_list)\n",
    "    # calculate number of correlations\n",
    "    n_corr = len(corr_list)\n",
    "    return average_corr, n_corr, datafolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_20.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_40.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_60.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_80.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_100.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_120.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_140.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_160.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_180.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_200.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_220.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_240.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_260.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_280.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_26956\\2163050758.py:110: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data table saved to: G:\\My Drive\\Results\\\\CAPS\\cluster_stats\\data_table_300.csv\n"
     ]
    }
   ],
   "source": [
    "# running get clusters\n",
    "\n",
    "\n",
    "number_of_clusters = 40\n",
    "project_dict_epi = {\n",
    "        \"User\": \"raulh87\",\n",
    "        \"Dataset\": \"CAPS_epi\",\n",
    "        \"Session\": \"\",\n",
    "        \"Task\": \"resting_state\",\n",
    "        \"Participants\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,17,18,19,22,23,27,28,30,31,34,36,37],\n",
    "        \"Runs\": [1],\n",
    "        \"Specie\": \"D\",\n",
    "        \"Atlas_type\": \"Nitzsche\",\n",
    "    }\n",
    "\n",
    "project_dict_K9 = {\n",
    "        \"User\": \"raulh87\",\n",
    "        \"Dataset\": \"CAPS_K9\",\n",
    "        \"Session\": \"\",\n",
    "        \"Task\": \"resting_state\",\n",
    "        \"Participants\": [],\n",
    "        \"Runs\": [1],\n",
    "        \"Specie\": \"D\",\n",
    "        \"Atlas_type\": \"Nitzsche\",\n",
    "    }\n",
    "\n",
    "#HERE-------------------\n",
    "\n",
    "experiment = 'CAPS'\n",
    "results_path = r\"G:\\My Drive\\Results\\\\\" + experiment + r\"\\cluster_stats\"\n",
    "\n",
    "\n",
    "for number_of_clusters in [20,40,60,80,100,120,140,160,180,200,220,240,260,280,300]:\n",
    "\n",
    "    data_table_path = os.path.join(results_path, 'data_table_' + str(number_of_clusters) + '.csv')\n",
    "\n",
    "    clusters_epi,clusters_ID_epi = get_clusters(project_dict_epi, number_of_clusters)\n",
    "    clusters_K9,clusters_ID_K9 = get_clusters(project_dict_K9, number_of_clusters)\n",
    "\n",
    "    # initialize data_table\n",
    "    data_table = pd.DataFrame(columns=['ID_epi', 'N_voxels_epi', 'ID_K9', 'N_voxels_K9', 'Union', 'Dice_coeff', 'Overlap', 'Index', 'Expected_index', 'Max_index', 'ARI'])\n",
    "\n",
    "    # calculate total number of voxels\n",
    "    n_voxels = sum(len(v) for v in clusters_epi.values())\n",
    "    n_voxels2 = sum(len(v) for v in clusters_K9.values())\n",
    "    # make sure the number of voxels is the same, if not, raise an error\n",
    "    if n_voxels != n_voxels2:\n",
    "        raise ValueError('The number of voxels in the two cluster maps is different')\n",
    "\n",
    "    for n_epi in clusters_ID_epi:\n",
    "        for n_K9 in clusters_ID_K9:\n",
    "            dice_coeff = 2*len(set(clusters_epi[n_epi]) & set(clusters_K9[n_K9]))/(len(clusters_epi[n_epi]) + len(clusters_K9[n_K9]))\n",
    "            # For Adjusted Rand Index\n",
    "            overlap = len(set(clusters_epi[n_epi]) & set(clusters_K9[n_K9]))\n",
    "            index = comb(overlap, 2)\n",
    "            sum_a = len(clusters_epi[n_epi])\n",
    "            sum_b = len(clusters_K9[n_K9])\n",
    "            expected = comb(sum_a, 2) * comb(sum_b, 2) / comb(n_voxels, 2)\n",
    "            max_index = 0.5 * (comb(sum_a, 2) + comb(sum_b, 2))\n",
    "            ari = (index - expected) / (max_index - expected) if max_index != expected else 0\n",
    "\n",
    "\n",
    "            new_row = {\n",
    "                'ID_epi': n_epi,\n",
    "                'N_voxels_epi': len(clusters_epi[n_epi]),\n",
    "                'ID_K9': n_K9,\n",
    "                'N_voxels_K9': len(clusters_K9[n_K9]),\n",
    "                'Union': len(set(clusters_epi[n_epi]) & set(clusters_K9[n_K9])),\n",
    "                'Dice_coeff': dice_coeff,\n",
    "                'Overlap': overlap,\n",
    "                'Index': index,\n",
    "                'Expected_index': expected,\n",
    "                'Max_index': max_index,\n",
    "                'ARI': ari,\n",
    "            }\n",
    "            # add the new row to the data_table\n",
    "            data_table = pd.concat([data_table, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    # Clean up table\n",
    "    # filter out the rows with Overlap = 0\n",
    "    data_table = data_table[data_table['Overlap'] != 0]\n",
    "    # sort the data_table by Overlap\n",
    "    data_table = data_table.sort_values(by='Overlap', ascending=False)\n",
    "    \n",
    "    # save the data_table\n",
    "    data_table.to_csv(data_table_path, index=False)\n",
    "    print('Data table saved to: ' + data_table_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of homogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject 1 cluster 1.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 2 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 3 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 4 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 5 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 6 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 7 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 8 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 9 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 10 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 11 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 12 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 13 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 14 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 15 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 17 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 18 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 19 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 22 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 23 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 27 cluster 1.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 28 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 30 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 31 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 34 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 36 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 37 cluster 1.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_001.csv\n",
      "Processing subject 1 cluster 2.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 2 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 3 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 4 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 5 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 6 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 7 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 8 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 9 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 10 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 11 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 12 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 13 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 14 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 15 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 17 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 18 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 19 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 22 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 23 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 27 cluster 2.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 28 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 30 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 31 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 34 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 36 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 37 cluster 2.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_002.csv\n",
      "Processing subject 1 cluster 3.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 2 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 3 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 4 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 5 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 6 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 7 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 8 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 9 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 10 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 11 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 12 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 13 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 14 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 15 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 17 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 18 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 19 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 22 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 23 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 27 cluster 3.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 28 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 30 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 31 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 34 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 36 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 37 cluster 3.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_003.csv\n",
      "Processing subject 1 cluster 4.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 2 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 3 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 4 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 5 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 6 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 7 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 8 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 9 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 10 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 11 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 12 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 13 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 14 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 15 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 17 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 18 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 19 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 22 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 23 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 27 cluster 4.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 28 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 30 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 31 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 34 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 36 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 37 cluster 4.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_004.csv\n",
      "Processing subject 1 cluster 5.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 2 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 3 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 4 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 5 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 6 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 7 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 8 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 9 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 10 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 11 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 12 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 13 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 14 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 15 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 17 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 18 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 19 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 22 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 23 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 27 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 28 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 30 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 31 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 34 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 36 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 37 cluster 5.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_005.csv\n",
      "Processing subject 1 cluster 6.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 2 cluster 6.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 3 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 4 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 5 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 6 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 7 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 8 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 9 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 10 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 11 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 12 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 13 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 14 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 15 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 17 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 18 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 19 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 22 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 23 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 27 cluster 6.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 28 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 30 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 31 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 34 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 36 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 37 cluster 6.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_006.csv\n",
      "Processing subject 1 cluster 7.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 2 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 3 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 4 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 5 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 6 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 7 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 8 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 9 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 10 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 11 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 12 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 13 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 14 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 15 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 17 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 18 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 19 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 22 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 23 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 27 cluster 7.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 28 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 30 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 31 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 34 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 36 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 37 cluster 7.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_007.csv\n",
      "Processing subject 1 cluster 8.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 2 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 3 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 4 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 5 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 6 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 7 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 8 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 9 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 10 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 11 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 12 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 13 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 14 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 15 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 17 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 18 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 19 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 22 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 23 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 27 cluster 8.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 28 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 30 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 31 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 34 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 36 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 37 cluster 8.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_008.csv\n",
      "Processing subject 1 cluster 9.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 2 cluster 9.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 3 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 4 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 5 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 6 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 7 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 8 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 9 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 10 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 11 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 12 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 13 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 14 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 15 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 17 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 18 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 19 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 22 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 23 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 27 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 28 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 30 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 31 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 34 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 36 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 37 cluster 9.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_009.csv\n",
      "Processing subject 1 cluster 10.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 2 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 3 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 4 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 5 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 6 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 7 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 8 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 9 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 10 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 11 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 12 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 13 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 14 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 15 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 17 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 18 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 19 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 22 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 23 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 27 cluster 10.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 28 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 30 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 31 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 34 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 36 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 37 cluster 10.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_010.csv\n",
      "Processing subject 1 cluster 11.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 2 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 3 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 4 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 5 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 6 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 7 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 8 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 9 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 10 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 11 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 12 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 13 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 14 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 15 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 17 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 18 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 19 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 22 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 23 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 27 cluster 11.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 28 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 30 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 31 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 34 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 36 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 37 cluster 11.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_011.csv\n",
      "Processing subject 1 cluster 12.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 2 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 3 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 4 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 5 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 6 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 7 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 8 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 9 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 10 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 11 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 12 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 13 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 14 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 15 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 17 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 18 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 19 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 22 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 23 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 27 cluster 12.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 28 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 30 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 31 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 34 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 36 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 37 cluster 12.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_012.csv\n",
      "Processing subject 1 cluster 13.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 2 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 3 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 4 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 5 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 6 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 7 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 8 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 9 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 10 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 11 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 12 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 13 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 14 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 15 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 17 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 18 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 19 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 22 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 23 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 27 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 28 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 30 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 31 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 34 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 36 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 37 cluster 13.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_013.csv\n",
      "Processing subject 1 cluster 14.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 2 cluster 14.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 3 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 4 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 5 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 6 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 7 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 8 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 9 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 10 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 11 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 12 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 13 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 14 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 15 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 17 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 18 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 19 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 22 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 23 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 27 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 28 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 30 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 31 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 34 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 36 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 37 cluster 14.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_014.csv\n",
      "Processing subject 1 cluster 15.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 2 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 3 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 4 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 5 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 6 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 7 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 8 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 9 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 10 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 11 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 12 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 13 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 14 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 15 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 17 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 18 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 19 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 22 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 23 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 27 cluster 15.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 28 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 30 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 31 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 34 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 36 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 37 cluster 15.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_015.csv\n",
      "Processing subject 1 cluster 16.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 2 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 3 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 4 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 5 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 6 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 7 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 8 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 9 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 10 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 11 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 12 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 13 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 14 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 15 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 17 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 18 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 19 cluster 16.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 22 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 23 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 27 cluster 16.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 28 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 30 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 31 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 34 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 36 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 37 cluster 16.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_016.csv\n",
      "Processing subject 1 cluster 17.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 2 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 3 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 4 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 5 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 6 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 7 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 8 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 9 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 10 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 11 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 12 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 13 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 14 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 15 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 17 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 18 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 19 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 22 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 23 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 27 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 28 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 30 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 31 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 34 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 36 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 37 cluster 17.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_017.csv\n",
      "Processing subject 1 cluster 18.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 2 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 3 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 4 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 5 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 6 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 7 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 8 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 9 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 10 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 11 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 12 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 13 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 14 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 15 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 17 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 18 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 19 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 22 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 23 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 27 cluster 18.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 28 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 30 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 31 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 34 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 36 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 37 cluster 18.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_018.csv\n",
      "Processing subject 1 cluster 19.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 2 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 3 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 4 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 5 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 6 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 7 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 8 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 9 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 10 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 11 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 12 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 13 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 14 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 15 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 17 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 18 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 19 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 22 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 23 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 27 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 28 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 30 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 31 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 34 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 36 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 37 cluster 19.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_019.csv\n",
      "Processing subject 1 cluster 20.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 2 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 3 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 4 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 5 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 6 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 7 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 8 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 9 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 10 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 11 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 12 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 13 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 14 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 15 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 17 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 18 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 19 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 22 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 23 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 27 cluster 20.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 28 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 30 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 31 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 34 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 36 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 37 cluster 20.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_020.csv\n",
      "Processing subject 1 cluster 21.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 2 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 3 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 4 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 5 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 6 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 7 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 8 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 9 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 10 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 11 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 12 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 13 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 14 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 15 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 17 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 18 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 19 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 22 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 23 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 27 cluster 21.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 28 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 30 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 31 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 34 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 36 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 37 cluster 21.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_021.csv\n",
      "Processing subject 1 cluster 22.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 2 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 3 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 4 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 5 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 6 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 7 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 8 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 9 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 10 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 11 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 12 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 13 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 14 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 15 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 17 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 18 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 19 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 22 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 23 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 27 cluster 22.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 28 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 30 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 31 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 34 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 36 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 37 cluster 22.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_022.csv\n",
      "Processing subject 1 cluster 23.0 with 300 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\raul_\\AppData\\Local\\Temp\\ipykernel_25260\\3490253131.py:40: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, row], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 2 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 3 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 4 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 5 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 6 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 7 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 8 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 9 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 10 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 11 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 12 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 13 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 14 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 15 cluster 23.0 with 300 clusters\n",
      "Results saved in: G:\\My Drive\\Results\\\\CAPS\\cluster_homogeinity\\homogeneity_300_023.csv\n",
      "Processing subject 17 cluster 23.0 with 300 clusters\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cluster_number_list = [20,40,60,80,100,120,140,160,180,200,220,240,260,280,300]\n",
    "# flip the list\n",
    "cluster_number_list = cluster_number_list[::-1]\n",
    "\n",
    "project_dict = {\n",
    "        \"User\": \"raulh87\",\n",
    "        \"Dataset\": \"CAPS_K9\",\n",
    "        \"Session\": \"\",\n",
    "        \"Task\": \"resting_state\",\n",
    "        \"Participants\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,17,18,19,22,23,27,28,30,31,34,36,37],\n",
    "        \"Runs\": [1],\n",
    "        \"Specie\": \"D\",\n",
    "        \"Atlas_type\": \"Nitzsche\",\n",
    "    }\n",
    "\n",
    "experiment = 'CAPS'\n",
    "if os.name == 'nt': # Windows\n",
    "    folder_to_save = r\"G:\\My Drive\\Results\\\\\" + experiment + r\"\\cluster_homogeinity\"\n",
    "else: # Linux\n",
    "    folder_to_save = r\"/mnt/a471/userdata/raulh87/data/CAPS_K9/results/homogeneity\"\n",
    "\n",
    "\n",
    "for number_of_clusters in cluster_number_list:\n",
    "    clusters,clusters_ID_list = get_clusters(project_dict, number_of_clusters)\n",
    "\n",
    "    for cluster_ID in clusters_ID_list:\n",
    "        # create file name\n",
    "        file_name = folder_to_save + '\\\\' + 'homogeneity_' + str(number_of_clusters) + '_' + str(int(cluster_ID)).zfill(3) + '.csv'\n",
    "        # load results if exist\n",
    "        if os.path.exists(file_name):\n",
    "            results = pd.read_csv(file_name)\n",
    "        else:\n",
    "            results = pd.DataFrame(columns=['sub_N', 'average_corr', 'n_corr'])\n",
    "        vox_list = clusters[cluster_ID]\n",
    "        for sub_N in project_dict['Participants']:\n",
    "            # print progress\n",
    "            print('Processing subject ' + str(sub_N) + ' cluster ' + str(cluster_ID) + ' with ' + str(number_of_clusters) + ' clusters')\n",
    "            # check if the subject is already in the results\n",
    "            if sub_N in results['sub_N'].values:\n",
    "                continue\n",
    "            # get the average correlation and number of correlations\n",
    "            average_corr, n_corr, datafolder = get_homogeinity(project_dict,sub_N,vox_list)\n",
    "            row = pd.DataFrame([[sub_N, average_corr, n_corr]], columns=['sub_N', 'average_corr', 'n_corr'])\n",
    "            results = pd.concat([results, row], ignore_index=True)\n",
    "\n",
    "            # determine folder to save\n",
    "            # folder_to_save = os.path.join(datafolder, project_dict['Dataset'], 'results', 'homogeneity')\n",
    "\n",
    "            # create folder if it does not exist\n",
    "            if not os.path.exists(folder_to_save):\n",
    "                os.makedirs(folder_to_save)\n",
    "\n",
    "            # save the results\n",
    "            results.to_csv(os.path.join(folder_to_save, file_name), index=False)\n",
    "            print('Results saved in: ' + os.path.join(folder_to_save, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'CAPS'\n",
    "folder_to_save = r\"G:\\My Drive\\Results\\\\\" + experiment + r\"\\cluster_homogeinity\"\n",
    "file_name = folder_to_save + '\\\\' + 'homogeneity_' + str(number_of_clusters) + '_' + str(int(cluster_ID)).zfill(3) + '.csv'\n",
    "# create folder if it does not exist\n",
    "if not os.path.exists(folder_to_save):\n",
    "    os.makedirs(folder_to_save)\n",
    "results.to_csv(os.path.join(folder_to_save, file_name), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homogeneity_20_001.csv\n"
     ]
    }
   ],
   "source": [
    "file_name = 'homogeneity_' + str(number_of_clusters) + '_' + str(int(cluster_ID)).zfill(3) + '.csv'\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001\n"
     ]
    }
   ],
   "source": [
    "# print integer and padded to the left version of cluster_ID\n",
    "print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
